{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.callbacks as pl_callbacks\n",
    "import torch\n",
    "import eq\n",
    "import wandb\n",
    "from tqdm.notebook import trange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing catalog from /home/zekai/repos/recast/data/ANSS_MultiCatalog.\n"
     ]
    }
   ],
   "source": [
    "catalog = eq.catalogs.ANSS_MultiCatalog(mag_completeness=4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    dl_train = catalog.train.get_dataloader()\n",
    "    dl_val = catalog.val.get_dataloader()\n",
    "    dl_test = catalog.test.get_dataloader()\n",
    "\n",
    "    # model = eq.models.RecurrentTPP(**config)\n",
    "    model = eq.models.RecurrentTPP()\n",
    "    model = model.to(device)\n",
    "\n",
    "    epochs = 200\n",
    "    avg_train_loss_list = []\n",
    "    avg_val_loss_list = []\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                                  lr=config[\"learning_rate\"], \n",
    "                                  betas=config[\"betas\"],\n",
    "                                  weight_decay=config[\"weight_decay\"])\n",
    "    \n",
    "    best_model_path = \"temp_best_model\"\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in trange(epochs):\n",
    "        running_training_loss = []\n",
    "        model.train()\n",
    "        for i, data in enumerate(dl_train):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            nll = model.nll_loss(data).mean()\n",
    "            nll.backward()\n",
    "            optimizer.step()\n",
    "            running_training_loss.append(nll.item())\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_val_loss = []\n",
    "            for i, data in enumerate(dl_val):\n",
    "                data = data.to(device)\n",
    "                nll = model.nll_loss(data).mean()\n",
    "                running_val_loss.append(nll.item())\n",
    "\n",
    "        avg_val_loss = np.mean(running_val_loss)\n",
    "\n",
    "        avg_train_loss_list.append(np.mean(running_training_loss))\n",
    "        avg_val_loss_list.append(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    best_model = torch.load(best_model_path)\n",
    "    with torch.no_grad():\n",
    "        running_test_loss = []\n",
    "        for i, data in enumerate(dl_test):\n",
    "            data = data.to(device)\n",
    "            nll = best_model.nll_loss(data).mean()\n",
    "            running_test_loss.append(nll.item())\n",
    "    avg_test_loss = np.mean(running_test_loss)\n",
    "\n",
    "    return avg_test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd220aaa75d4db4ab795728ac468100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m res \u001b[39m=\u001b[39m train({\u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m1e-4\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m              \u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m: (\u001b[39m0.9\u001b[39m, \u001b[39m0.999\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m              \u001b[39m\"\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.01\u001b[39m})\n",
      "\u001b[1;32m/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dl_val):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb#W6sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         nll \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mnll_loss(data)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         running_val_loss\u001b[39m.\u001b[39mappend(nll\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zekai/repos/recast/notebooks/Zekai/hyperparameter_sweep/sweep_vanilla_torch.ipynb#W6sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m avg_val_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(running_val_loss)\n",
      "File \u001b[0;32m~/repos/recast/eq/models/recurrent.py:161\u001b[0m, in \u001b[0;36mRecurrentTPP.nll_loss\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnll_loss\u001b[39m(\u001b[39mself\u001b[39m, batch: eq\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mBatch) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    152\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39m    Compute negative log-likelihood (NLL) for a batch of event sequences.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m        nll: NLL of each sequence, shape (batch_size,)\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m     context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_context(batch)  \u001b[39m# (B, L, C)\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[39m# Inter-event times\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     inter_time_dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_inter_time_dist(context)\n",
      "File \u001b[0;32m~/repos/recast/eq/models/recurrent.py:120\u001b[0m, in \u001b[0;36mRecurrentTPP.get_context\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    117\u001b[0m     feat_list\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_extra_features(batch\u001b[39m.\u001b[39mextra_feat))\n\u001b[1;32m    118\u001b[0m features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(feat_list, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m rnn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(features)[\u001b[39m0\u001b[39m][:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m    121\u001b[0m output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mpad(rnn_output, (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m))  \u001b[39m# (B, L, C)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/eq/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/eq/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eq/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1102\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1101\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m   1103\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n\u001b[1;32m   1104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m   1106\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = train({\"learning_rate\":1e-4,\n",
    "             \"betas\": (0.9, 0.999),\n",
    "             \"weight_decay\": 0.01})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    try:\n",
    "        dl_train = catalog.train.get_dataloader()\n",
    "        dl_val = catalog.val.get_dataloader()\n",
    "        dl_test = catalog.test.get_dataloader()\n",
    "\n",
    "        model = eq.models.RecurrentTPP(**config)\n",
    "        model = model.to(device)\n",
    "\n",
    "        epochs = 200\n",
    "        avg_train_loss_list = []\n",
    "        avg_val_loss_list = []\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                                    lr=config[\"learning_rate\"], \n",
    "                                    betas=config[\"betas\"],\n",
    "                                    weight_decay=config[\"weight_decay\"])\n",
    "        \n",
    "        best_model_path = \"temp_best_model\"\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        for epoch in trange(epochs):\n",
    "            running_training_loss = []\n",
    "            model.train()\n",
    "            for i, data in enumerate(dl_train):\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                nll = model.nll_loss(data).mean()\n",
    "                nll.backward()\n",
    "                optimizer.step()\n",
    "                running_training_loss.append(nll.item())\n",
    "            \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                running_val_loss = []\n",
    "                for i, data in enumerate(dl_val):\n",
    "                    data = data.to(device)\n",
    "                    nll = model.nll_loss(data).mean()\n",
    "                    running_val_loss.append(nll.item())\n",
    "\n",
    "            avg_val_loss = np.mean(running_val_loss)\n",
    "\n",
    "            avg_train_loss_list.append(np.mean(running_training_loss))\n",
    "            avg_val_loss_list.append(avg_val_loss)\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        best_model = torch.load(best_model_path)\n",
    "        with torch.no_grad():\n",
    "            running_test_loss = []\n",
    "            for i, data in enumerate(dl_test):\n",
    "                data = data.to(device)\n",
    "                nll = best_model.nll_loss(data).mean()\n",
    "                running_test_loss.append(nll.item())\n",
    "        avg_test_loss = np.mean(running_test_loss)\n",
    "    \n",
    "    except Exception:\n",
    "        avg_test_loss = float(\"nan\")\n",
    "\n",
    "    return avg_test_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
