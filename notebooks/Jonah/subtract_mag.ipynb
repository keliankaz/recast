{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import pytorch_lightning.callbacks as pl_callbacks\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import eq\n",
    "\n",
    "\n",
    "from eq.data import Catalog, InMemoryDataset, Sequence, default_catalogs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing catalog from /home/gcl/RA/jonahk/recast/data/SCEDC.\n",
      "Loading existing catalog from /home/gcl/RA/jonahk/recast/data/ANSS_MultiCatalog.\n"
     ]
    }
   ],
   "source": [
    "catalog1 = eq.catalogs.SCEDC(include_loc=False)\n",
    "catalog2 = eq.catalogs.ANSS_MultiCatalog(    \n",
    "    num_sequences=99,\n",
    "    t_end_days=1*365,\n",
    "    mag_completeness=4.5,\n",
    "    minimum_mainshock_mag=6.0,\n",
    "    include_loc=False,\n",
    "    include_depth=False\n",
    ")\n",
    "# catalog3=eq.catalogs.White() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def combine_catalogs_sequences(seqlist):\n",
    "    sequences = []\n",
    "    for seq in seqlist:\n",
    "        sequences.append(seq)\n",
    "    return InMemoryDataset(sequences=sequences)\n",
    "\n",
    "def build_seqlist(catalogs):\n",
    "    train_sequences = []\n",
    "    for catalog in catalogs:\n",
    "        for seq in range(len(catalog)):\n",
    "            train_sequences.append(catalog[seq])\n",
    "    return train_sequences\n",
    "\n",
    "def subtract_magnitudes(sequences, mag_completeness):\n",
    "    for seq in sequences:\n",
    "        seq.mag -= mag_completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2600, 2.3700, 2.1600,  ..., 2.3500, 2.0600, 2.1000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog1.train[0].mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#subtract mag_completeness from catalogs\n",
    "subtract_magnitudes(catalog1.train, 2.0)\n",
    "subtract_magnitudes(catalog2.train, 4.5)\n",
    "subtract_magnitudes(catalog1.val, 2.0)\n",
    "subtract_magnitudes(catalog2.val, 4.5)\n",
    "subtract_magnitudes(catalog1.test, 2.0)\n",
    "subtract_magnitudes(catalog2.test, 4.5)\n",
    "\n",
    "#make the 2 catalogs into a list for training and val data\n",
    "catalogs_train = []\n",
    "catalogs_train.append(catalog1.train)\n",
    "catalogs_train.append(catalog2.train)\n",
    "\n",
    "catalogs_val = []\n",
    "catalogs_val.append(catalog1.val)\n",
    "catalogs_val.append(catalog2.val)\n",
    "\n",
    "catalogs_test = []\n",
    "catalogs_test.append(catalog1.test)\n",
    "catalogs_test.append(catalog2.test)\n",
    "\n",
    "#build list of catalog sequences\n",
    "seqlist_train = build_seqlist(catalogs_train)\n",
    "seqlist_val = build_seqlist(catalogs_val)\n",
    "seqlist_test = build_seqlist(catalogs_test)\n",
    "\n",
    "#combined the sequences into one memory i=object to train on\n",
    "combined_cat_train = combine_catalogs_sequences(seqlist_train)\n",
    "combined_cat_val = combine_catalogs_sequences(seqlist_val)\n",
    "combined_cat_test = combine_catalogs_sequences(seqlist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2600, 0.3700, 0.1600,  ..., 0.3500, 0.0600, 0.1000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog1.train[0].mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_combined_train = combined_cat_train.get_dataloader( batch_size=5, shuffle=True)\n",
    "dl_combined_val = combined_cat_val.get_dataloader( batch_size=5, shuffle=True)\n",
    "test = catalog1.test.get_dataloader( batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/gcl/RA/jonahk/miniconda3/envs/DS-discovery/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ hypernet_time │ Linear  │  3.2 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ hypernet_mag  │ Linear  │     33 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ rnn           │ GRU     │  3.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ dropout       │ Dropout │      0 │\n",
       "└───┴───────────────┴─────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ hypernet_time │ Linear  │  3.2 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ hypernet_mag  │ Linear  │     33 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ rnn           │ GRU     │  3.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ dropout       │ Dropout │      0 │\n",
       "└───┴───────────────┴─────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 6.7 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 6.7 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 6.7 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 6.7 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3ec2090dff4f49bc3c3cf61b899212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/gcl/RA/jonahk/miniconda3/envs/DS-discovery/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/\n",
       "data_connector.py:490: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly \n",
       "recommended that you turn shuffling off for val/test dataloaders.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/gcl/RA/jonahk/miniconda3/envs/DS-discovery/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/\n",
       "data_connector.py:490: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly \n",
       "recommended that you turn shuffling off for val/test dataloaders.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/gcl/RA/jonahk/miniconda3/envs/DS-discovery/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/\n",
       "data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be\n",
       "a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/gcl/RA/jonahk/miniconda3/envs/DS-discovery/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/\n",
       "data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be\n",
       "a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/gcl/RA/jonahk/miniconda3/envs/DS-discovery/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/\n",
       "data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may \n",
       "be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus \n",
       "on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/gcl/RA/jonahk/miniconda3/envs/DS-discovery/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/\n",
       "data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may \n",
       "be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus \n",
       "on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = combined_cat_train.sequences[0].t_end\n",
    "N = np.mean([len(seq) for seq in combined_cat_train])\n",
    "mag_mean = np.mean([combined_cat_train.sequences[0].mag.mean().item() for seq in combined_cat_train])\n",
    "tau_mean = T/N\n",
    "mag_completness = 0.6\n",
    "\n",
    "anss_double_model = eq.models.RecurrentTPP(\n",
    "    mag_mean = mag_mean,\n",
    "    tau_mean = tau_mean,\n",
    "    mag_completeness = mag_completness,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "    # ModelCheckpoints saves the model with the best validation loss\n",
    "checkpoint = pl_callbacks.ModelCheckpoint(monitor=\"total_val_loss\")\n",
    "\n",
    "    # EarlyStopping stops training if the validation loss doesn't improve by more than 1e-3 for 20 epochs\n",
    "early_stopping = pl_callbacks.EarlyStopping(monitor=\"total_val_loss\", patience=50, min_delta=1e-5)\n",
    "\n",
    "    # RichProgressBar adds a nice and more functional progress bar\n",
    "progress_bar = pl_callbacks.RichProgressBar()\n",
    "\n",
    "    # Trainer set up training and validation loops with previous specs\n",
    "trainer = pl.Trainer(devices=1,max_epochs=1000, callbacks=[checkpoint, early_stopping, progress_bar],log_every_n_steps=1)\n",
    "\n",
    "trainer.fit(anss_double_model, dl_combined_train, dl_combined_val)\n",
    "checkpoint.best_model_path\n",
    "anss_double_model.load_from_checkpoint(checkpoint.best_model_path)\n",
    "trainer.test(anss_double_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ hypernet_time │ Linear  │  3.2 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ hypernet_mag  │ Linear  │     33 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ rnn           │ GRU     │  3.5 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ dropout       │ Dropout │      0 │\n",
       "└───┴───────────────┴─────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ hypernet_time │ Linear  │  3.2 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ hypernet_mag  │ Linear  │     33 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ rnn           │ GRU     │  3.5 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ dropout       │ Dropout │      0 │\n",
       "└───┴───────────────┴─────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 6.7 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 6.7 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 6.7 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 6.7 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2160c836cd4e1daf6c92d5ccb1a7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1000` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b819404d024048b48d017ea025cd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">   Runningstage.testing    </span>┃<span style=\"font-weight: bold\">                           </span>┃\n",
       "┃<span style=\"font-weight: bold\">          metric           </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -14.236465454101562    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      total_test_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -14.236465454101562    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m  Runningstage.testing   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m                           \u001b[0m┃\n",
       "┃\u001b[1m \u001b[0m\u001b[1m         metric          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -14.236465454101562   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     total_test_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -14.236465454101562   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': -14.236465454101562, 'total_test_loss': -14.236465454101562}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare results to single catalog training\n",
    "single_train = catalog1.train.get_dataloader(batch_size=1, shuffle=True)\n",
    "single_val = catalog1.val.get_dataloader(batch_size=1, shuffle=True)\n",
    "\n",
    "T = catalog1.train[0].t_end\n",
    "\n",
    "N = np.mean([len(seq) for seq in catalog1.train])\n",
    "mag_mean = np.mean([catalog1.train[0].mag.mean().item() for seq in catalog1.train])\n",
    "tau_mean = T/N\n",
    "\n",
    "single_model = eq.models.RecurrentTPP(\n",
    "    mag_mean = mag_mean,\n",
    "    tau_mean = tau_mean,\n",
    "    mag_completeness=catalog1.metadata['mag_completeness'],\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "    # ModelCheckpoints saves the model with the best validation loss\n",
    "checkpoint = pl_callbacks.ModelCheckpoint(monitor=\"total_val_loss\")\n",
    "\n",
    "    # EarlyStopping stops training if the validation loss doesn't improve by more than 1e-3 for 20 epochs\n",
    "early_stopping = pl_callbacks.EarlyStopping(monitor=\"total_val_loss\", patience=10, min_delta=1e-5)\n",
    "\n",
    "    # RichProgressBar adds a nice and more functional progress bar\n",
    "progress_bar = pl_callbacks.RichProgressBar()\n",
    "\n",
    "    # Trainer set up training and validation loops with previous specs\n",
    "trainer = pl.Trainer(devices=1,max_epochs=1000, callbacks=[checkpoint, early_stopping, progress_bar],log_every_n_steps=1)\n",
    "\n",
    "trainer.fit(single_model, single_train, single_val)\n",
    "checkpoint.best_model_path\n",
    "single_model.load_from_checkpoint(checkpoint.best_model_path)\n",
    "trainer.test(single_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(\n",
       "  inter_times: [125663],\n",
       "  arrival_times: [125662],\n",
       "  t_start: 0.0,\n",
       "  t_end: 14243.998,\n",
       "  t_nll_start: 12053.0,\n",
       "  mag: [125662]\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog1.test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "It should hold 0 <= t_start <= t_nll_start < t_end. Received 0.0, 12053.0, 4000.0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m test_seq \u001b[39m=\u001b[39m catalog1\u001b[39m.\u001b[39mtest[\u001b[39m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[39m# Past events that we condition on\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m past_seq \u001b[39m=\u001b[39m test_seq\u001b[39m.\u001b[39;49mget_subsequence(\u001b[39m0\u001b[39;49m, t_forecast)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Observed events in the 7-day forecast window\u001b[39;00m\n\u001b[1;32m      9\u001b[0m observed_seq \u001b[39m=\u001b[39m test_seq\u001b[39m.\u001b[39mget_subsequence(t_forecast, t_forecast \u001b[39m+\u001b[39m duration)\n",
      "File \u001b[0;32m~/recast/eq/data/sequence.py:181\u001b[0m, in \u001b[0;36mSequence.get_subsequence\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_sequence_attrs:\n\u001b[1;32m    179\u001b[0m         other_attr[key] \u001b[39m=\u001b[39m value[mask]\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m--> 181\u001b[0m \u001b[39mreturn\u001b[39;00m Sequence(\n\u001b[1;32m    182\u001b[0m     inter_times\u001b[39m=\u001b[39;49mnew_inter_times,\n\u001b[1;32m    183\u001b[0m     t_start\u001b[39m=\u001b[39;49mstart,\n\u001b[1;32m    184\u001b[0m     t_nll_start\u001b[39m=\u001b[39;49m\u001b[39mmax\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mt_nll_start, start),\n\u001b[1;32m    185\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_attr,\n\u001b[1;32m    186\u001b[0m )\n",
      "File \u001b[0;32m~/recast/eq/data/sequence.py:126\u001b[0m, in \u001b[0;36mSequence.__init__\u001b[0;34m(self, inter_times, t_start, t_nll_start, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[39mself\u001b[39m[key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_bounds\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(value\u001b[39m.\u001b[39mbounds)\n\u001b[1;32m    124\u001b[0m     \u001b[39mself\u001b[39m[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(value)\n\u001b[0;32m--> 126\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_args()\n\u001b[1;32m    127\u001b[0m \u001b[39m# Move all tensors to the same device as inter_times\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minter_times\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/recast/eq/data/sequence.py:196\u001b[0m, in \u001b[0;36mSequence._validate_args\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check if the event sequence is valid and the shapes are correct.\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_start \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_nll_start \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_end):\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    197\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt should hold 0 <= t_start <= t_nll_start < t_end. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_start\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_nll_start\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_end\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m     )\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39many(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minter_times \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m    202\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    203\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNegative inter-event times detected, this isn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt a valid event sequence.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: It should hold 0 <= t_start <= t_nll_start < t_end. Received 0.0, 12053.0, 4000.0."
     ]
    }
   ],
   "source": [
    "t_forecast = 4000\n",
    "duration = 7\n",
    "num_samples = 10_000\n",
    "\n",
    "test_seq = catalog1.test[0]\n",
    "# Past events that we condition on\n",
    "past_seq = test_seq.get_subsequence(0, t_forecast)\n",
    "# Observed events in the 7-day forecast window\n",
    "observed_seq = test_seq.get_subsequence(t_forecast, t_forecast + duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    anss_double_model.cuda()\n",
    "    past_seq.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_forecast = anss_double_model.sample(batch_size=num_samples, duration=duration, past_seq=past_seq, return_sequences=True)\n",
    "single_forecast = single_model.sample(batch_size=num_samples, duration=duration, past_seq=past_seq, return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq.visualization.visualize_trajectories(test_seq, multi_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq.visualization.visualize_trajectories(test_seq, single_forecast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS-discovery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
